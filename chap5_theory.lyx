#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Section*
5.6 The Normal Distribution
\end_layout

\begin_layout Standard

\series bold
Definition 5.6.1: 
\series default
A random variable 
\begin_inset Formula $X$
\end_inset

 has the normal distribution with mean 
\begin_inset Formula $\mu$
\end_inset

 and variance 
\begin_inset Formula $\sigma^{2}$
\end_inset

 (
\begin_inset Formula $-\infty<\mu<\infty$
\end_inset

 and 
\begin_inset Formula $\sigma>0$
\end_inset

) if 
\begin_inset Formula $X$
\end_inset

 has a continuous distribution with the following p.d.f:
\end_layout

\begin_layout Standard
\begin_inset Formula $f(x|\mu,\sigma^{2})=\frac{1}{(2\pi)^{\frac{1}{2}}\text{\ensuremath{\sigma}}}e^{\frac{-(x-\mu)^{2}}{2\sigma^{2}}}$
\end_inset


\end_layout

\begin_layout Standard

\series bold
Theorem 5.6.2: 
\series default
Moment Generating Functions
\end_layout

\begin_layout Standard
\begin_inset Formula $\psi(t)=exp(\mu t+\frac{1}{2}\sigma^{2}t^{2})$
\end_inset

 for 
\begin_inset Formula $-\infty<t<\infty$
\end_inset


\end_layout

\begin_layout Standard

\series bold
Theorem 5.6.4: 
\series default
If 
\begin_inset Formula $X$
\end_inset

 has the normal distribution with mean 
\begin_inset Formula $\mu$
\end_inset

 and variance 
\begin_inset Formula $\sigma^{2}$
\end_inset

 and if 
\begin_inset Formula $Y=aX+b$
\end_inset

 , where 
\begin_inset Formula $a$
\end_inset

 and 
\begin_inset Formula $b$
\end_inset

 are given constants and 
\begin_inset Formula $a\neq0$
\end_inset

, then 
\begin_inset Formula $Y$
\end_inset

 has the normal distribution with mean 
\begin_inset Formula $a\mu+b$
\end_inset

 variance 
\begin_inset Formula $a^{2}\sigma^{2}$
\end_inset


\end_layout

\begin_layout Standard

\series bold
Definition 5.6.2 Standard Normal Distribution 
\series default
The normal distribution with mean 0 and variance 1 is called the standard
 normal distribution.
 The p.d.f of the standard normal distribution is usually denoted by the symbol
 
\begin_inset Formula $\phi$
\end_inset

 and the c.d.f is denote by the sumbo 
\begin_inset Formula $\Phi$
\end_inset

.
 Thus,
\end_layout

\begin_layout Standard
\begin_inset Formula $\phi(x)=f(x|0,1)=\frac{1}{(2\pi)^{\frac{1}{2}}}exp(\frac{-1}{2}x^{2})$
\end_inset

 and 
\begin_inset Formula $\Phi(x)=\intop_{-\infty}^{x}\phi(u)du$
\end_inset


\end_layout

\begin_layout Standard

\series bold
Theorem 5.6.5 
\series default
Consequences of Symmetry.
 For all x and all 
\begin_inset Formula $0<p<1$
\end_inset

,
\end_layout

\begin_layout Standard
\begin_inset Formula $\Phi(-x)=1-\Phi(x)$
\end_inset

 and 
\begin_inset Formula $\Phi^{-1}(p)=-\Phi^{-1}(1-p)$
\end_inset


\end_layout

\begin_layout Standard

\series bold
Theorem 5.6.6 
\series default
Converting Normal Distributions to Standard.
 Let X has the normal distribution with mean 
\begin_inset Formula $\mu$
\end_inset

 and variance 
\begin_inset Formula $\sigma^{2}$
\end_inset

 .
 Let 
\begin_inset Formula $F$
\end_inset

 be the c.d.f of 
\begin_inset Formula $X$
\end_inset

 .
 Then 
\begin_inset Formula $Z=(X-\mu)/\sigma$
\end_inset

 has the standard normal distribution.
\end_layout

\begin_layout Standard

\series bold
Theorem 5.6.7 
\series default
If the random variables 
\begin_inset Formula $X_{1},...,X_{k}$
\end_inset

 are independent and if 
\begin_inset Formula $X_{i}$
\end_inset

 has the normal distribution with mean 
\begin_inset Formula $\mu_{i}$
\end_inset

 and variance 
\begin_inset Formula $\sigma_{i}^{2}$
\end_inset

 then sum 
\begin_inset Formula $X_{1}+...+X_{k}$
\end_inset

 has the normal distribution with mean 
\begin_inset Formula $\mu_{1}+...+\mu_{k}$
\end_inset

 and variance 
\begin_inset Formula $\sigma_{1}^{2}+...+\sigma_{k}^{2}$
\end_inset

.
 (Prove that using moment generating function 
\begin_inset Formula $\psi(t)$
\end_inset

)
\end_layout

\begin_layout Standard

\series bold
Corollary 5.6.1 
\series default
If the random variables 
\begin_inset Formula $X_{1},...,X_{k}$
\end_inset

 are independent, if 
\begin_inset Formula $X_{i}$
\end_inset

 has the normal distribution with mean 
\begin_inset Formula $\mu_{i}$
\end_inset

 and variance 
\begin_inset Formula $\sigma_{i}^{2}$
\end_inset

 
\begin_inset Formula $(i=1,...,k)$
\end_inset

 if 
\begin_inset Formula $a_{1},...,a_{k}$
\end_inset

 and 
\begin_inset Formula $b$
\end_inset

 are constants for which at least one of the values 
\begin_inset Formula $a_{1},...,a_{k}$
\end_inset

 is different from 0, then variable 
\begin_inset Formula $a_{1}X_{1}+..+a_{k}X_{k}+b$
\end_inset

 has the normal distribution with mean 
\begin_inset Formula $a_{1}\mu_{1}+...+a_{k}\mu_{k}+b$
\end_inset

 and variance 
\begin_inset Formula $a_{1}^{2}\sigma_{1}^{2}+...+a_{k}^{2}\sigma_{k}^{2}.$
\end_inset


\end_layout

\begin_layout Standard

\series bold
Definition 5.6.3 
\series default
Sample Mean.
 Let 
\begin_inset Formula $X_{1},...,X_{n}$
\end_inset

 be random variables.
 The average of these 
\begin_inset Formula $n$
\end_inset

 random variables, 
\begin_inset Formula $\frac{1}{n}\sum_{i=1}^{n}X_{i}$
\end_inset

 is called their sample mean and is commonly denoted 
\begin_inset Formula $\bar{X_{n}}$
\end_inset

.
\end_layout

\begin_layout Standard

\series bold
Corollary 5.6.2.
 
\series default
Suppose that random variables 
\begin_inset Formula $X_{1},...,X_{n}$
\end_inset

 form a random sample from the normal distribution with mean 
\begin_inset Formula $\mu$
\end_inset

 and variance 
\begin_inset Formula $\sigma^{2}$
\end_inset

, and let 
\begin_inset Formula $\bar{X_{n}}$
\end_inset

 denote their sample mean.
 Then 
\begin_inset Formula $\bar{X_{n}}$
\end_inset

has the normal distribution with mean 
\begin_inset Formula $\mu$
\end_inset

 and variance 
\begin_inset Formula $\sigma^{2}/n$
\end_inset


\end_layout

\begin_layout Standard

\series bold
Definition 5.6.4.
 
\series default
Lognomal
\end_layout

\begin_layout Standard
Distribution.
 If 
\begin_inset Formula $\log(X)$
\end_inset

 has the normal distribution with mean 
\begin_inset Formula $\mu$
\end_inset

 and variance 
\begin_inset Formula $\sigma^{2}$
\end_inset

, we say that 
\begin_inset Formula $X$
\end_inset

 has the 
\emph on
lognormal distribution 
\emph default
with parameter 
\begin_inset Formula $\mu$
\end_inset

 and 
\begin_inset Formula $\sigma^{2}$
\end_inset

.
\end_layout

\begin_layout Section*
5.7 The Gamma Distributions
\end_layout

\begin_layout Standard

\series bold
Definition 5.7.1 The Gamma Function: 
\series default
For each positive number 
\begin_inset Formula $\alpha$
\end_inset

 , let the value 
\begin_inset Formula $\Gamma(\alpha)$
\end_inset

 be defined by the following intergral: 
\end_layout

\begin_layout Standard
\begin_inset Formula $\Gamma(\alpha)=\int_{0}^{\infty}x^{\alpha-1}e^{-x}dx$
\end_inset

 .
 The function 
\begin_inset Formula $\Gamma$
\end_inset

defined by Eq.
 (5.7.2) for 
\begin_inset Formula $\alpha>0$
\end_inset

 is called the 
\emph on
gamma function.
 
\end_layout

\begin_layout Standard
For example: 
\begin_inset Formula $\Gamma(1)=\int_{0}^{\infty}e^{-x}dx=1$
\end_inset


\end_layout

\begin_layout Standard

\series bold
Theorem 5.7.1 
\series default
If 
\begin_inset Formula $\alpha>1$
\end_inset

, then: 
\begin_inset Formula $\Gamma(\alpha)=(\alpha-1)\Gamma(\alpha-1).$
\end_inset


\end_layout

\begin_layout Standard

\series bold
Theorem 5.7.2 
\series default
For every positive integer 
\begin_inset Formula $n$
\end_inset

,
\end_layout

\begin_layout Standard
\begin_inset Formula $\Gamma(n)=\int_{0}^{\infty}x^{n-1}e^{-x}dx=(n-1)!$
\end_inset

.
\end_layout

\begin_layout Standard

\series bold
Theorem 5.7.3 
\series default
For each 
\begin_inset Formula $\alpha>0$
\end_inset

 and each 
\begin_inset Formula $\beta>0$
\end_inset

,
\end_layout

\begin_layout Standard
\begin_inset Formula $\int_{0}^{\infty}x^{\alpha-1}exp(-\beta x)dx=\frac{\Gamma(\alpha)}{\beta^{\alpha}}$
\end_inset


\end_layout

\begin_layout Standard

\series bold
Theorem 5.7.4 Stirling's Formula.
 
\series default

\begin_inset Formula $\lim_{x\rightarrow\infty}\frac{(2\pi)^{1/2}x^{x-1/2}e^{-x}}{\Gamma(x)}=1$
\end_inset


\end_layout

\begin_layout Standard

\series bold
The Gamma Distribution
\end_layout

\begin_layout Standard

\series bold
Definition 5.7.2 
\series default
Gamma Distributions.
 Let 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

 be postitive numbers.
 A random variable 
\begin_inset Formula $X$
\end_inset

 has the 
\emph on
gamma distribution with parameters 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

 
\emph default
if 
\begin_inset Formula $X$
\end_inset

 has a continuous distribution for which the p.d.f is 
\end_layout

\begin_layout Standard
\begin_inset Formula $f(x|\alpha,\beta)=\begin{cases}
0 & x\leq0\\
\text{\ensuremath{\frac{\beta^{\alpha}}{\Gamma(\alpha)}x^{\alpha-1}e^{-\beta x}}} & x>0
\end{cases}$
\end_inset


\end_layout

\begin_layout Standard

\series bold
Theorem 5.7.5 
\series default
Moments.
 Let 
\begin_inset Formula $X$
\end_inset

 have the gamma distribution with parameters 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $k=1,2,...$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $E(X^{k})=\frac{\Gamma(\alpha+k)}{\beta^{k}\Gamma(\alpha)}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $E[X]=\frac{\alpha}{\beta}$
\end_inset

 and 
\begin_inset Formula $Var(X)=\frac{\alpha}{\beta^{2}}$
\end_inset


\end_layout

\begin_layout Standard

\series bold
Theorem 5.7.6 Moment Generating Function 
\series default
.
 Let 
\begin_inset Formula $X$
\end_inset

 have the gamma distribution with parameters 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

.
 The m.g.f of 
\begin_inset Formula $X$
\end_inset

 is :
\end_layout

\begin_layout Standard
\begin_inset Formula $\psi(t)=(\frac{\beta}{\beta-t})^{\alpha}$
\end_inset

 for 
\begin_inset Formula $t<\beta$
\end_inset

.
\end_layout

\begin_layout Standard

\series bold
Theorem 5.7.7 
\series default
If the random variables 
\begin_inset Formula $X_{1},...,X_{k}$
\end_inset

 are independent, and if 
\begin_inset Formula $X_{i}$
\end_inset

 has the gamma distribution with parameters 
\begin_inset Formula $\alpha_{i}$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

 (
\begin_inset Formula $i=1,..,k)$
\end_inset

, then the sum 
\begin_inset Formula $X_{1}+...+X_{k}$
\end_inset

 has the gamma distribution with parameters 
\begin_inset Formula $\alpha_{1}+...+\alpha_{k}$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

.
\end_layout

\begin_layout Standard

\series bold
The Exponential Distributions
\end_layout

\begin_layout Standard

\series bold
Definition 5.7.3 
\series default
Exponential Distributions.
 Let 
\begin_inset Formula $\beta>0$
\end_inset

.
 A random variable 
\begin_inset Formula $X$
\end_inset

 has the 
\emph on
exponential distribution with parameter 
\begin_inset Formula $\beta$
\end_inset

 if 
\begin_inset Formula $X$
\end_inset

 has a continuous 
\emph default
distribution with the p.d.f
\end_layout

\begin_layout Standard
\begin_inset Formula $f(x|\beta)=\begin{cases}
\beta e^{-\beta x} & x>0\\
0 & x\leq0
\end{cases}$
\end_inset


\end_layout

\begin_layout Standard
We can see Exponential Distributions is special case of Gamma distribution
 with 
\begin_inset Formula $\alpha=1$
\end_inset

 so 
\begin_inset Formula $\Gamma(\alpha)=1$
\end_inset


\end_layout

\begin_layout Standard

\series bold
Theorem 5.7.8 
\series default
The exponential distribution with parameter 
\begin_inset Formula $\beta$
\end_inset

 is the same as the gamma distribution with parameters 
\begin_inset Formula $\alpha=1$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

.
 If 
\begin_inset Formula $X$
\end_inset

 has the exponential distribution with parameter 
\begin_inset Formula $\beta$
\end_inset

 , then
\end_layout

\begin_layout Standard
\begin_inset Formula $E(X)=\frac{1}{\beta}$
\end_inset

 and 
\begin_inset Formula $Var(X)=\frac{1}{\beta^{2}}$
\end_inset

 and the m.g.f of 
\begin_inset Formula $X$
\end_inset

 is : 
\begin_inset Formula $\psi(t)=\frac{\beta}{\beta-t}$
\end_inset

 for 
\begin_inset Formula $t<\beta$
\end_inset

.
\end_layout

\begin_layout Standard
Exponetial distribution have a memoryless property similar to that stated
 in Theorem 5.5.5 for geometric distributions.
\end_layout

\begin_layout Standard

\series bold
Theorem 5.7.9 
\series default
Memoryless property of Exponential Distributions.
 Let 
\begin_inset Formula $X$
\end_inset

 have exponential distribution with parameter 
\begin_inset Formula $\beta$
\end_inset

 and let 
\begin_inset Formula $t>0$
\end_inset

 .
 Then for every number 
\begin_inset Formula $h>0$
\end_inset

,
\end_layout

\begin_layout Standard
\begin_inset Formula $P(X\geq t+h|X\geq t)=P(X\geq h)$
\end_inset

.
\end_layout

\begin_layout Standard
The exponential distribution has been used effectively as an approximate
 distribution for such variables as the lengths of the lives of various
 products.
\end_layout

\begin_layout Standard

\series bold
Theorem 5.7.10 
\series default
Suppose that the variabels 
\begin_inset Formula $X_{1},...,X_{n}$
\end_inset

 form a random sample from the exponential distribution with parameter 
\begin_inset Formula $\beta$
\end_inset

.
 Then the distribution of 
\begin_inset Formula $Y_{1}=\min\{X_{1},...,X_{n}\}$
\end_inset

 will be the exponential distribution with parameter 
\begin_inset Formula $n\beta$
\end_inset

.
 
\end_layout

\begin_layout Standard
Because of memoryless property of exponential distribution, we have 
\begin_inset Formula $Y_{2}=\min\{X_{1},...,X_{n-1})$
\end_inset

 will be the exponential distribution with parameter 
\begin_inset Formula $(n-1)\beta$
\end_inset

.
\end_layout

\begin_layout Standard

\series bold
Theorem 5.7.11 
\series default
Suppose that the variables 
\begin_inset Formula $X_{1},...,X_{n}$
\end_inset

 form a random sample from the exponential distribution with parameter 
\begin_inset Formula $\beta$
\end_inset

, Let 
\begin_inset Formula $Z_{1}\leq Z_{2}\leq...\leq Z_{n}$
\end_inset

 be the random variables 
\begin_inset Formula $X_{1},...,X_{n}$
\end_inset

 sorted from smallest to largest.
 For each 
\begin_inset Formula $k=2,...,n$
\end_inset

 , let 
\begin_inset Formula $Y_{k}=Z_{k}-Z_{k-1}$
\end_inset

then distribution of 
\begin_inset Formula $Y_{k}$
\end_inset

is the exponential distribution with parameter 
\begin_inset Formula $(n+1-k)\beta$
\end_inset

.
\end_layout

\begin_layout Standard

\series bold
Relation to the Poisson Process.
\end_layout

\begin_layout Standard

\series bold
Definition 5.4.1 
\series default
Poisson Distribution .
 Let 
\begin_inset Formula $\lambda>0$
\end_inset

.
 A random variable 
\begin_inset Formula $X$
\end_inset

 has the 
\emph on
Possion Distribution with mean 
\begin_inset Formula $\lambda$
\end_inset

 
\emph default
if the p.d.f of 
\begin_inset Formula $X$
\end_inset

 is as follows:
\end_layout

\begin_layout Standard
\begin_inset Formula $f(x|\lambda)=\begin{cases}
\frac{e^{-\lambda}\lambda^{x}}{x!} & x=0,1,2,...\\
0 & otherwise
\end{cases}$
\end_inset


\end_layout

\begin_layout Standard

\series bold
Definition 5.4.2 Poisson Process
\series default
.
 A Poisson process with rate 
\begin_inset Formula $\lambda$
\end_inset

 per unite time is a process that satisfies the following two properties.
\end_layout

\begin_layout Standard
i.
 The number of arrivals in every fixed interval of time of length 
\begin_inset Formula $t$
\end_inset

 has the Poisson distribution with mean 
\begin_inset Formula $\lambda t$
\end_inset

.
\end_layout

\begin_layout Standard
ii.
 The numbers of arrivals in every collection of disjoint time intervals
 are independent.
\end_layout

\begin_layout Standard

\series bold
Theorem 5.7.12 
\series default
Times between Arrivals in a Poisson Process.
 Suppose that arrivals occur according to a Poisson process with rate 
\begin_inset Formula $\beta$
\end_inset

.
 Let 
\begin_inset Formula $Z_{k}$
\end_inset

 be the time until the kth arrival for 
\begin_inset Formula $k=1,2,...$
\end_inset

 .
 Define 
\begin_inset Formula $Y_{1}=Z_{1}$
\end_inset

 and 
\begin_inset Formula $Y_{k}=Z_{k}-Z_{k-1}$
\end_inset

 for 
\begin_inset Formula $k\geq2$
\end_inset

.
 Then 
\begin_inset Formula $Y_{1},Y_{2},...$
\end_inset

 are i.i.d.
 and they each have the exponential distribution.
\end_layout

\begin_layout Standard
An exponential distribution is often in a practical problem to represent
 the distribution of the time that elapses before the occurence of some
 event.
\end_layout

\begin_layout Standard
If the events being considered occur in accordance with Poisson process,
 then both the waiting time until an event occurs and the period of time
 between any two successive events will have exponential distributions.
\end_layout

\begin_layout Standard
Combine 
\series bold
Theorem 5.7.12 
\series default
with 
\series bold
Theorem 5.7.7 
\series default
to obtain the following:
\end_layout

\begin_layout Standard

\series bold
Corollary 5.7.1 
\series default
Time until kth Arrial.
 In the situation of Theorem 5.7.12, the distribution of 
\begin_inset Formula $Z_{k}$
\end_inset

 is the gamma distribution with parameters 
\begin_inset Formula $k$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

.
\end_layout

\begin_layout Subsection*
The Beta Distributions
\end_layout

\begin_layout Standard

\series bold
Moments of Beta Distributions
\end_layout

\begin_layout Standard

\series bold
Theorem 5.8.3.
 Moments 
\series default
Suppose that 
\begin_inset Formula $X$
\end_inset

 has the beta distribution with parameters 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

, Then for each positive integer 
\begin_inset Formula $k$
\end_inset

,
\end_layout

\begin_layout Standard
\begin_inset Formula $E[X^{k}]=\frac{\alpha(\alpha+1)...(\alpha+k-1)}{(\alpha+\beta)(\alpha+\beta+1)...(\alpha+\beta+k-1)}$
\end_inset


\end_layout

\begin_layout Standard
In particular: 
\end_layout

\begin_layout Standard
\begin_inset Formula $E[X]=\frac{\alpha}{\alpha+\beta}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $Var(X)=\frac{\alpha\beta}{(\alpha+\beta)^{2}(\alpha+\beta+1)}$
\end_inset


\end_layout

\begin_layout Standard

\series bold
Theorem 4.7.1 Law of Total Probability for Expectations.
 
\series default
Let 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 be random variables such that 
\begin_inset Formula $Y$
\end_inset

 has finite mean.
 Then, 
\end_layout

\begin_layout Standard
\begin_inset Formula $E[E(Y|X)]=E[Y]$
\end_inset

.
\end_layout

\begin_layout Standard

\series bold
Theorem 5.8.4 
\series default
Let 
\begin_inset Formula $U$
\end_inset

 and 
\begin_inset Formula $V$
\end_inset

 be independent random variables with 
\begin_inset Formula $U$
\end_inset

 having the gamma distribution with parameters 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $1$
\end_inset

 and 
\begin_inset Formula $V$
\end_inset

 having the gamma distribution parameters 
\begin_inset Formula $\beta$
\end_inset

 and 
\begin_inset Formula $1$
\end_inset

.
 Then 
\end_layout

\begin_layout Itemize
\begin_inset Formula $X=U/(U+V)$
\end_inset

 and 
\begin_inset Formula $Y=U+V$
\end_inset

 are independent
\end_layout

\begin_layout Itemize
\begin_inset Formula $X$
\end_inset

 has the beta distribtion parameters 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

 , and
\end_layout

\begin_layout Itemize
\begin_inset Formula $Y$
\end_inset

 has the gamma distribution with parameters 
\begin_inset Formula $\alpha+\beta$
\end_inset

 and 
\begin_inset Formula $1$
\end_inset

.
\end_layout

\begin_layout Standard

\series bold
Summary
\end_layout

\begin_layout Standard
The family of beta distribution is a popular model for random variables
 that lie in the interval 
\begin_inset Formula $(0,1)$
\end_inset

, such as unknown proportions of success for sequences of Bernoulli trials.
 The mean of the beta distribution with parameters 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

 is 
\begin_inset Formula $\alpha/(\alpha+\beta)$
\end_inset

.
\end_layout

\begin_layout Subsection*
The Beta Function 
\end_layout

\begin_layout Standard

\series bold
Definition 5.8.1 
\series default
The Beta Function.
 For each positive 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

 , define 
\end_layout

\begin_layout Standard
\begin_inset Formula $B(\alpha,\beta)=\int_{0}^{1}x^{\alpha-1}(1-x)^{\beta-1}dx.$
\end_inset


\end_layout

\begin_layout Standard
The function 
\begin_inset Formula $B$
\end_inset

 is called the 
\emph on
beta function.
 
\end_layout

\begin_layout Standard

\series bold
Theorem 5.8.1 
\series default
For all 
\begin_inset Formula $\alpha,\beta>0,$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $B(\alpha,\beta)=\frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha+\beta)}$
\end_inset


\end_layout

\begin_layout Standard

\series bold
Definition of the Beta Distributions
\end_layout

\begin_layout Standard

\series bold
Definition 5.8.2 
\series default
Beta Distributions.
 Let 
\begin_inset Formula $\alpha,\beta>0$
\end_inset

 and let 
\begin_inset Formula $X$
\end_inset

 be a random variable with p.d.f.
\end_layout

\begin_layout Standard
\begin_inset Formula $f(x|\alpha,\beta)=\begin{cases}
\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha-1}(1-x)^{\beta-1} & 0<x<1\\
0 & otherwise
\end{cases}$
\end_inset


\end_layout

\begin_layout Standard
If 
\begin_inset Formula $\alpha=1$
\end_inset

 and 
\begin_inset Formula $\beta=1$
\end_inset

 then this distribution is uniform distribution on the interval 
\begin_inset Formula $[0,1]$
\end_inset

.
\end_layout

\begin_layout Standard

\series bold
Theorem 5.8.2 
\series default
Suppose that 
\begin_inset Formula $P$
\end_inset

 has the beta distribution with parameters 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

, and the condiational distribution of 
\begin_inset Formula $X$
\end_inset

 given 
\begin_inset Formula $P=p$
\end_inset

 is the binomial distibution with parameters 
\begin_inset Formula $n$
\end_inset

 and 
\begin_inset Formula $p$
\end_inset

.
 Then the conditional distribution of 
\begin_inset Formula $P$
\end_inset

 given 
\begin_inset Formula $X=x$
\end_inset

 is the beta distribution with parameters 
\begin_inset Formula $\alpha+x$
\end_inset

 and 
\begin_inset Formula $\beta+n-x$
\end_inset

.
\end_layout

\begin_layout Paragraph
5.9 The Multinomial Distributions 
\end_layout

\begin_layout Standard
This is general case of Binomial distribution (2 value), Multinomial ( >
 2 value possible).
\end_layout

\begin_layout Subsubsection*
Definition and Derivation of Multinomial Distributions
\end_layout

\begin_layout Standard

\series bold
Definition 5.9.1 Multinomial Distribution 
\series default
A disrete random vector 
\series bold

\begin_inset Formula $X=(X_{1},...,X_{k})$
\end_inset

 
\series default
is given by Equation:
\end_layout

\begin_layout Standard
\begin_inset Formula $f(\boldsymbol{x}|n,\boldsymbol{p})=P(\boldsymbol{X=x})=P(X_{1}=x_{1},...,X_{k}=x_{k})$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $=\begin{cases}
\tbinom{n}{x_{1},...,x_{k}}p_{1}^{x_{1}}...p_{k}^{x_{k}} & x_{1}+...+x_{k}=n,\\
0 & otherwise
\end{cases}$
\end_inset


\end_layout

\begin_layout Standard
Has the multinomial distribution with parameters 
\begin_inset Formula $n$
\end_inset

 and 
\series bold
p 
\series default
= 
\begin_inset Formula $(p_{1},...,p_{k})$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\tbinom{n}{x_{1},...,x_{k}}=\frac{n!}{x_{1}!x_{2}!...x_{k}!}
\]

\end_inset


\end_layout

\begin_layout Paragraph
Relation between the Multinomial and Binomial Distribution
\end_layout

\begin_layout Standard

\series bold
Theorem 5.9.1 
\series default
Suppose that the random vector 
\begin_inset Formula $\boldsymbol{X}=(X_{1},X_{2})$
\end_inset

 has the multinomial distribution with parameters 
\begin_inset Formula $n$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{p}=(p_{1},p_{2})$
\end_inset

.
 Then 
\begin_inset Formula $X_{1}$
\end_inset

 has the binomial distribution with parameters 
\begin_inset Formula $n$
\end_inset

 and 
\begin_inset Formula $p_{1}$
\end_inset

 and 
\begin_inset Formula $X_{2}=n-X_{1}$
\end_inset

.
\end_layout

\begin_layout Standard

\series bold
Corollary 5.9.1 
\series default
Suppose that the random vector 
\begin_inset Formula $X=(X_{1},...,X_{k})$
\end_inset

has the multinomial distribution with parameters 
\begin_inset Formula $n$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{p}=(p_{1},...,p_{k})$
\end_inset

.
 The marginal distribution of each variable 
\begin_inset Formula $X_{i}(i=1,...,k)$
\end_inset

 is the binomial distribution with parameters 
\begin_inset Formula $n$
\end_inset

 and 
\begin_inset Formula $p_{i}$
\end_inset

.
\end_layout

\begin_layout Standard

\series bold
Theorem 5.9.2 
\series default
Means, Variances, and Covariances.
 Let the random vector 
\begin_inset Formula $X$
\end_inset

 have the multinomial distributions with parameters 
\begin_inset Formula $n$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{p}$
\end_inset

.
 The means and variances of coordinates of 
\begin_inset Formula $X$
\end_inset

 are 
\end_layout

\begin_layout Standard
\begin_inset Formula $E[X_{i}]=np_{i}$
\end_inset

 and 
\begin_inset Formula $Var(X_{i})=np_{i}(1-p_{i})$
\end_inset

 for 
\begin_inset Formula $i=1,...,k$
\end_inset


\end_layout

\begin_layout Standard
Also, the covariances between the coordinates are 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Cov(X_{i},X_{j})=-np_{i}p_{j}
\]

\end_inset


\end_layout

\begin_layout Subsection*
5.10 The Bivariate Normal Distribution
\end_layout

\begin_layout Standard
The first family of multivariate continuous distributions for which we have
 a name is a generalization of the family of nomal distributions to two
 coordinates.
 There is more structure to a bivariate normal distribution than just a
 pair of normal marginal distributions.
\end_layout

\begin_layout Standard

\series bold
Theorem 5.10.1 
\series default
Suppose that 
\begin_inset Formula $Z_{1}$
\end_inset

 and 
\begin_inset Formula $Z_{2}$
\end_inset

 are independent random variables, each of which has the standard normal
 distribution.
 Let 
\begin_inset Formula $\mu_{1},\mu_{2},\sigma_{1},\sigma_{2}$
\end_inset

, and 
\begin_inset Formula $\rho$
\end_inset

 be constants such that 
\begin_inset Formula $-\infty<\mu_{i}<\infty(i=1,2)$
\end_inset

, 
\begin_inset Formula $\sigma_{i}>0(i=1,2)$
\end_inset

, and 
\begin_inset Formula $-1<\rho<1$
\end_inset

.
 Defined two new random variabels 
\begin_inset Formula $X_{1}$
\end_inset

 and 
\begin_inset Formula $X_{2}$
\end_inset

 as follows:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
X_{1}=\sigma_{1}Z_{1}+\mu_{1},
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
X_{2}=\sigma_{2}[\rho Z_{1}+(1-\rho^{2})^{1/2}Z_{2}]+\mu_{2}
\]

\end_inset

(5.10.1) 
\end_layout

\begin_layout Standard
The joint p.d.f.
 of 
\begin_inset Formula $X_{1}$
\end_inset

and 
\begin_inset Formula $X_{2}$
\end_inset

 is 
\end_layout

\begin_layout Standard
\begin_inset Formula $f(x_{1},x_{2})=\frac{1}{2\pi(1-\rho^{2})^{1/2}\sigma_{1}\sigma_{2}}exp\{-\frac{1}{2(1-\rho^{2})}[(\frac{x_{1}-\mu_{1}}{\sigma_{1}})^{2}-2\rho(\frac{x_{1}-\mu_{1}}{\sigma_{1}})(\frac{x_{2}-\mu_{2}}{\sigma_{2}})+(\frac{x_{2}-\mu_{2}}{\sigma_{2}})^{2}]\}$
\end_inset

 (5.10.2)
\end_layout

\begin_layout Standard

\series bold
Theorem 5.10.2 
\series default
Suppose that 
\begin_inset Formula $X_{1}$
\end_inset

and 
\begin_inset Formula $X_{2}$
\end_inset

 have the joint distribution whose p.d.f is given by Eq.
 (5.10.2).
 Then there exists independent standard normal random variables 
\begin_inset Formula $Z_{1}$
\end_inset

and 
\begin_inset Formula $Z_{2}$
\end_inset

such that Eqs.
 (5.10.1) hold.
 Also, the mean of 
\begin_inset Formula $X_{i}$
\end_inset

 is 
\begin_inset Formula $\mu_{i}$
\end_inset

 and variance of 
\begin_inset Formula $X_{i}$
\end_inset

 is 
\begin_inset Formula $\sigma_{i}^{2}$
\end_inset

 for 
\begin_inset Formula $i=1,2$
\end_inset

.
 Furthermore the correlation between 
\begin_inset Formula $X_{1}$
\end_inset

and 
\begin_inset Formula $X_{2}$
\end_inset

is 
\begin_inset Formula $\rho$
\end_inset

.
 Finally, the marginal distribution of 
\begin_inset Formula $X_{i}$
\end_inset

 is the normal distribution with mean 
\begin_inset Formula $\mu_{i}$
\end_inset

and variance 
\begin_inset Formula $\sigma_{i}^{2}$
\end_inset

 for 
\begin_inset Formula $i=1,2$
\end_inset

.
\end_layout

\begin_layout Paragraph*
Definition 5.10.1 
\series medium
Bivariate Normal Distributions.
 When the joint p.d.f.
 of two random variables 
\begin_inset Formula $X_{1}$
\end_inset

 and 
\begin_inset Formula $X_{2}$
\end_inset

 is of the form in Eq.
 (5.10.2), it is said that 
\begin_inset Formula $X_{1}$
\end_inset

 and 
\begin_inset Formula $X_{2}$
\end_inset

 have the 
\emph on
bivariate normal distribution with means 
\begin_inset Formula $\mu_{1}$
\end_inset

 and 
\begin_inset Formula $\mu_{2}$
\end_inset

, variances 
\begin_inset Formula $\sigma_{1}^{2}$
\end_inset

 and 
\begin_inset Formula $\sigma_{2}^{2}$
\end_inset

 and correlation 
\begin_inset Formula $\rho$
\end_inset

.
\end_layout

\begin_layout Subsection*
Properties of Bivariate Normal Distributions
\end_layout

\begin_layout Standard
For random variables with a bivariate normal distribution, we find that
 being independent is equivalent to being uncorrelated.
\end_layout

\begin_layout Paragraph*
Theorem 5.10.3 
\series medium
Independence and Correlation.
 Two random variables 
\begin_inset Formula $X_{1}$
\end_inset

and 
\begin_inset Formula $X_{2}$
\end_inset

 that have a bivariate normal distribution are independent if and only if
 they uncorrelated.
\end_layout

\begin_layout Standard
We have already seen in Example 4.6.4 that two random variables 
\begin_inset Formula $X_{1}$
\end_inset

and 
\begin_inset Formula $X_{2}$
\end_inset

with an arbitrary joint distribution can be uncorrelated without being independe
nt.
 Theorem 5.10.3 says that no such examples exist in which 
\begin_inset Formula $X_{1}$
\end_inset

 and 
\begin_inset Formula $X_{2}$
\end_inset

have a bivariate normal distribution\SpecialChar endofsentence

\end_layout

\begin_layout Standard
When the corelation is not zero, Theorem 5.10.2 gives the marginal distributions
 of bivariate normal random variabels.
 Combining the marginal and joint distributions allows us to find the conditiona
l distribution of each 
\begin_inset Formula $X_{i}$
\end_inset

 given the other one.
 The next theorem derives the conditional distributions using another technique.
\end_layout

\begin_layout Paragraph*
Theorem 5.10.4 
\series medium
Conditional Distributions.
 Let 
\begin_inset Formula $X_{1}$
\end_inset

 and 
\begin_inset Formula $X_{2}$
\end_inset

 have the bivariate normal distribution whose p.d.f.
 is Eq.
 (5.10.2).
 The conditional distribution of 
\begin_inset Formula $X_{2}$
\end_inset

 given that 
\begin_inset Formula $X_{1}=x_{1}$
\end_inset

 is the normal distribution with mean and variance given by
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
E[X_{2}|x_{1}]=\mu_{2}+\rho\sigma_{2}(\frac{x_{1}-\mu_{1}}{\sigma_{1}}),Var(X_{2}|x_{1})=(1-\rho^{2})\sigma_{2}^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
It is seen from Eq.
 (5.10.2) that the joint distribution of 
\begin_inset Formula $X_{2}$
\end_inset

 and 
\begin_inset Formula $X_{1}$
\end_inset

 is also bivariate normal with all of subscripts 
\begin_inset Formula $1$
\end_inset

 and 
\begin_inset Formula $2$
\end_inset

 switched on all the parameters.
 Hence, we can apply Theorem 5.10.4 to 
\begin_inset Formula $X_{2}$
\end_inset

 and 
\begin_inset Formula $X_{1}$
\end_inset

 to conclude that the conditional distribution of 
\begin_inset Formula $X_{1}$
\end_inset

given that 
\begin_inset Formula $X_{2}=x_{2}$
\end_inset

 must be the normal distribution with mean and variance.
\end_layout

\begin_layout Standard
\begin_inset Formula $E[X_{1}|x_{2}]=\mu_{1}+\rho\sigma_{1}(\frac{x_{2}-\mu_{2}}{\sigma_{2}}),Var(X_{1}|x_{2})=(1-\rho^{2})\sigma_{1}^{2}$
\end_inset

 (5.10.8)
\end_layout

\begin_layout Standard
We have now shown that each marginal distribution and each conditional distribut
ion of a bivariate normal distribution is a univariate normal distribution.
\end_layout

\begin_layout Standard
Some particular features of the conditional distribution of 
\begin_inset Formula $X_{2}$
\end_inset

 given that 
\begin_inset Formula $X_{1}=x_{1}$
\end_inset

 should be noted.
 If 
\begin_inset Formula $\rho\neq0$
\end_inset

, then 
\begin_inset Formula $E[X_{2}|x_{1}]$
\end_inset

 is a linear function of 
\begin_inset Formula $x_{1}$
\end_inset

.
 If 
\begin_inset Formula $\rho>0$
\end_inset

, the slope of this linear function is positive.
 If 
\begin_inset Formula $\rho<0$
\end_inset

, the slope of the function is negative.
 However, the variance of the conditional distribution of 
\begin_inset Formula $X_{2}$
\end_inset

 given that 
\begin_inset Formula $X_{1}=x_{1}$
\end_inset

 is 
\begin_inset Formula $(1-\rho^{2})\sigma_{2}^{2}$
\end_inset

 , which does not depend on 
\begin_inset Formula $x_{1}$
\end_inset

 .
 Furthermore, this variance of the conditional distribution of 
\begin_inset Formula $X_{2}$
\end_inset

 is smaller than the variance 
\begin_inset Formula $\sigma_{2}^{2}$
\end_inset

 of the marginal distribution of 
\begin_inset Formula $X_{2}$
\end_inset

.
 (We can say 
\begin_inset Formula $X_{1}$
\end_inset

 
\series bold
is more confident (
\begin_inset Formula $\sigma$
\end_inset

 smaller) when know 
\begin_inset Formula $X_{2}$
\end_inset

), 
\series default
In example 5.10.3, it says that MSE (=
\begin_inset Formula $E[(X_{2}-\bar{X_{2})^{2}]}$
\end_inset

 decrease).
\end_layout

\begin_layout Paragraph*

\series medium
Since the variance of the conditional distribution in Example 5.10.3 is 
\begin_inset Formula $(1-\rho^{2})\sigma_{2}^{2}$
\end_inset

, regardless of the known height 
\begin_inset Formula $x_{1}$
\end_inset

 of the person, it follows that the difficulty of predicting the person's
 weight is the same for a tall person, a short person, or a person of medium
 height.
 Furthermore, since the variance 
\begin_inset Formula $(1-\rho^{2})\sigma_{2}^{2}$
\end_inset

 decreases as 
\begin_inset Formula $|\rho|$
\end_inset

 increases, 
\series default
it follows that it is easier to predict a person's weight from her height
 when the person is selected from a population in which height and weight
 are highly correlated
\series medium
.
\end_layout

\begin_layout Subsection*
Linear Combinations 
\end_layout

\begin_layout Standard

\series bold
Theorem 5.10.5 
\series default
Linear combination of Bivariate Normals.
 Suppose that two random variables 
\begin_inset Formula $X_{1}$
\end_inset

 and 
\begin_inset Formula $X_{2}$
\end_inset

 have a bivariate normal distribution, for which the p.d.f.
 is specified by Eq.
 (5.10.2).
 Let 
\begin_inset Formula $Y=\alpha_{1}X_{1}+\alpha_{2}X_{2}+b$
\end_inset

, where 
\begin_inset Formula $a_{1},a_{2}$
\end_inset

 and 
\begin_inset Formula $b$
\end_inset

 are arbitrary given constants.
 Then 
\begin_inset Formula $Y$
\end_inset

 has normal distribution with mean 
\begin_inset Formula $a_{1}\mu_{1}+a_{2}\mu_{2}+b$
\end_inset

 and variance 
\begin_inset Formula $a_{1}^{2}\sigma_{1}^{2}+a_{2}^{2}\sigma_{2}^{2}+2a_{1}a_{2}\rho\sigma_{1}\sigma_{2}$
\end_inset

.
\end_layout

\begin_layout Standard

\series bold
Proof: 
\series default
Because joint of 
\begin_inset Formula $X_{1}$
\end_inset

 and 
\begin_inset Formula $X_{2}$
\end_inset

 is bivariate normals, so exists 
\begin_inset Formula $Z_{1}$
\end_inset

 and 
\begin_inset Formula $Z_{2}$
\end_inset

 such that Eq.
 5.10.1 holds.
\end_layout

\begin_layout Paragraph*
Summary 
\end_layout

\begin_layout Standard
If a random vector 
\begin_inset Formula $(X,Y)$
\end_inset

 has a bivariate normal distribution, then every linear combination 
\begin_inset Formula $aX+bY+c$
\end_inset

 has a normal distribution.
 In particular, the marginal distributions of 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are normal.
 Also, the conditional distribution of 
\begin_inset Formula $X$
\end_inset

 given 
\begin_inset Formula $Y=y$
\end_inset

 is normal with the conditional mean being a linear function of 
\begin_inset Formula $y$
\end_inset

 and the conditional variance being constant in 
\begin_inset Formula $y$
\end_inset

.
 (Similarly, for the conditional distribution of 
\begin_inset Formula $Y$
\end_inset

 given 
\begin_inset Formula $X=x$
\end_inset

) A more thorough treatment of the bivariate normal distributions and higher-dim
ensional generalizations can be found in this book by D.F.
 Morrison (1990).
\end_layout

\end_body
\end_document
